## Overview and Objectives
The proposed solution is written in Python and was executed using the free Kaggle GPU environments. The solution improves a microsoft-phi2 base model by 
implementing a RAG method, model fine-tuning and prompt engineering. The improved model was used to answer questions from the 3rd Generation Partnership Project (3GPP) documents.
The model achieved an accuracy of 0.622 on the public leaderboard

## ETL Processes
 a. The first process was to create a chroma-db for all the rel18 documents.
  i. The entire rel18 documents was used to build the chroma db
  ii. The embedding model used was the "BAAI/bge-small-en-v1.5" from hugging face
  iii. A chunk size of 128 and a chunk overlap of 20 was used
  iv. The entire process was executed on the Kaggle GPU environment (GPU T4x2) and it ran for 9596.9 seconds.
  v. Here is the link to the fully executed notebook (https://www.kaggle.com/code/tobby18/llmachromadb-indexing)
  vi. The output was a chroma.sqlite3 database with embeddings. The size is 7.03gb
  
 b. Create context for all the training questions.
    i. In this process, I created a context using the chroma-db (created in step a) for all the training questions. The context and the training questions are used to fine-tune the model
   ii.To create the context, the 3GPP release number in the questions were removed. This enhances the accuracy of the context generated
   iii. A similarity top_k was used to generate the context. k was set to 1 and similarity cut-off set to 0.5. The entire process was executed in 218 seconds (GPU T4x2)
   iv. Here is the link to the fully executed notebook. https://www.kaggle.com/code/tobby18/rag-inference-for-training
   v. The output is a pickle of the training questions and the context generated by the RAG 
   
 c. Train the model with the created context
    i. The output of step b is used to train the model. The fine tuning was done using the Peft QLoRA technique. 
   ii. The model was loaded with a 4-bit quantization
   iii. 4 trained models were created by changing the hyperparameters of the LoraConfig. 
   iv. Here is the link to the kaggle notebook https://www.kaggle.com/code/tobby18/rag-fine-tuning
   v. A training accuracy of 53.42% was recorded (other accuracy recorded are 52%, 50% and 53%). The training process took 8953.7 sec on the Kaggle GPU T4x2
   vi. The output is an adapter config json file and a safetensor
 
 d. Inference using the trained model + RAG + prompt engineering

## Data Modelling


## Inference


## Performance and Metrics
